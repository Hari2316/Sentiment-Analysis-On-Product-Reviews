{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4574de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5897cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Processing_XML_Reviews_Dictionnaire(ListReviews):\n",
    "    count = 0\n",
    "    Review = []\n",
    "    Reviews = {}\n",
    "    for i in range(len(ListReviews)):\n",
    "        if ListReviews[i] != '</review>\\n':\n",
    "            if ListReviews[i] == '<review>\\n' and ListReviews[i+1] == '<unique_id>\\n':\n",
    "                # unique_id\n",
    "                Review.append('unique_id/'+ListReviews[i+2])\n",
    "            #if ListReviews[i] == '</unique_id>\\n' and ListReviews[i+1] == '<unique_id>\\n':\n",
    "                #unique_idN\n",
    "                #Review.append('unique_id/'+ListReviews[i+2])\n",
    "            if  ListReviews[i] == '<asin>\\n':\n",
    "                #asin\n",
    "                Review.append('asin/'+ListReviews[i+1])    \n",
    "            if  ListReviews[i] == '<product_name>\\n':\n",
    "                #productName\n",
    "                Review.append('product_name/'+ListReviews[i+1])\n",
    "            #if  ListReviews[i] == '</product_type>\\n' and ListReviews[i+1] == '<product_type>\\n' :\n",
    "                #here we append the producttype\n",
    "                #Review.append('product_type/'+ListReviews[i+2])\n",
    "            if ListReviews[i] == '<helpful>\\n':\n",
    "                #helpful\n",
    "                Review.append('helpful/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<rating>\\n':\n",
    "                Review.append('rating/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<title>\\n':\n",
    "                Review.append('title/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<date>\\n':\n",
    "                Review.append('date/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<reviewer>\\n':\n",
    "                Review.append('reviewer/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<reviewer_location>\\n':\n",
    "                Review.append('reviewer_location/'+ListReviews[i+1])\n",
    "            if ListReviews[i] == '<review_text>\\n':\n",
    "                Review.append('review_text/'+ListReviews[i+1])\n",
    "        elif ListReviews[i] == '</review>\\n':\n",
    "            count = count + 1\n",
    "            r = 'review'+ str(count) \n",
    "            Reviews[r] = Review\n",
    "            #nfargou list\n",
    "            Review = []\n",
    "    return Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cf64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Porcessing_Dictonnary_ToDataFrame(Dict):\n",
    "    #on prepare notre dataframe pour les donn√©es\n",
    "    df = pd.DataFrame(columns=['unique_id','asin','product_name','helpful','rating','title',\n",
    "                    'date','reviewer','reviewer_location','review_text'])\n",
    "    count = 0\n",
    "    for i,k in Dict.items():\n",
    "        df.loc[count] = [k[0].split(\"/\")[1].split(\"\\n\")[0],k[1].split(\"/\")[1].split(\"\\n\")[0]\n",
    "                              ,k[2].split(\"/\")[1].split(\"\\n\")[0],k[3].split(\"/\")[1].split(\"\\n\")[0]\n",
    "                              ,k[4].split(\"/\")[1].split(\"\\n\")[0],k[5].split(\"/\")[1].split(\"\\n\")[0]\n",
    "                              ,k[6].split(\"/\")[1].split(\"\\n\")[0],k[7].split(\"/\")[1].split(\"\\n\")[0]\n",
    "                              ,k[8].split(\"/\")[1].split(\"\\n\")[0],k[9].split(\"/\")[1].split(\"\\n\")[0]\n",
    "        ]\n",
    "        count = count + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f5331a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_data/apparel\\negative.review\n",
      "sorted_data/apparel\\positive.review\n",
      "sorted_data/automotive\\negative.review\n",
      "sorted_data/automotive\\positive.review\n",
      "sorted_data/baby\\negative.review\n",
      "sorted_data/baby\\positive.review\n",
      "sorted_data/beauty\\negative.review\n",
      "sorted_data/beauty\\positive.review\n",
      "sorted_data/books\\negative.review\n",
      "sorted_data/books\\positive.review\n",
      "sorted_data/camera_&_photo\\negative.review\n",
      "sorted_data/camera_&_photo\\positive.review\n",
      "sorted_data/cell_phones_&_service\\negative.review\n",
      "sorted_data/cell_phones_&_service\\positive.review\n",
      "sorted_data/computer_&_video_games\\negative.review\n",
      "sorted_data/computer_&_video_games\\positive.review\n",
      "sorted_data/dvd\\negative.review\n",
      "sorted_data/dvd\\positive.review\n",
      "sorted_data/electronics\\negative.review\n",
      "sorted_data/electronics\\positive.review\n",
      "sorted_data/gourmet_food\\negative.review\n",
      "sorted_data/gourmet_food\\positive.review\n",
      "sorted_data/grocery\\negative.review\n",
      "sorted_data/grocery\\positive.review\n",
      "sorted_data/health_&_personal_care\\negative.review\n",
      "sorted_data/health_&_personal_care\\positive.review\n",
      "sorted_data/jewelry_&_watches\\negative.review\n",
      "sorted_data/jewelry_&_watches\\positive.review\n",
      "sorted_data/kitchen_&_housewares\\negative.review\n",
      "sorted_data/kitchen_&_housewares\\positive.review\n",
      "sorted_data/magazines\\negative.review\n",
      "sorted_data/magazines\\positive.review\n",
      "sorted_data/music\\negative.review\n",
      "sorted_data/music\\positive.review\n",
      "sorted_data/musical_instruments\\negative.review\n",
      "sorted_data/musical_instruments\\positive.review\n",
      "sorted_data/office_products\\negative.review\n",
      "sorted_data/office_products\\positive.review\n",
      "sorted_data/outdoor_living\\negative.review\n",
      "sorted_data/outdoor_living\\positive.review\n",
      "sorted_data/software\\negative.review\n",
      "sorted_data/software\\positive.review\n",
      "sorted_data/sports_&_outdoors\\negative.review\n",
      "sorted_data/sports_&_outdoors\\positive.review\n",
      "sorted_data/tools_&_hardware\\negative.review\n",
      "sorted_data/tools_&_hardware\\positive.review\n",
      "sorted_data/toys_&_games\\negative.review\n",
      "sorted_data/toys_&_games\\positive.review\n",
      "sorted_data/video\\negative.review\n",
      "sorted_data/video\\positive.review\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "indir = 'sorted_data/'\n",
    "PositifReviews = []\n",
    "NegativeReviews = []\n",
    "for root, dirs, filenames in os.walk(indir):\n",
    "    #print(root,dirs,filenames)\n",
    "    for f in filenames:\n",
    "        #log = open(os.path.join(root, f), 'r').readlines()\n",
    "        #print(os.path.join(root, f))\n",
    "        #filee = open(log,'r').readlines()\n",
    "        if f == \"positive.review\":\n",
    "            log = open(os.path.join(root, f), 'r').readlines()\n",
    "            PositifReviews.append(Processing_XML_Reviews_Dictionnaire(log))\n",
    "            #print(log)\n",
    "            print(os.path.join(root, f))\n",
    "        if f == \"negative.review\":\n",
    "            log = open(os.path.join(root, f), 'r').readlines()\n",
    "            NegativeReviews.append(Processing_XML_Reviews_Dictionnaire(log))\n",
    "            #print(log)\n",
    "            print(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0ffa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "584\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(PositifReviews))\n",
    "print(len(NegativeReviews))\n",
    "print(len(PositifReviews[1]))# automotive/positive.review\t 584\n",
    "print(len(PositifReviews[2]))#baby/positive.review\t\t1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab50fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unique_id/B0007QCQA4:good_sneakers:christopher_w._damico_\"macman\"\\n', 'asin/B0007QCQA4\\n', \"product_name/adidas Originals Men's Superstar II Basketball Shoe: Apparel\\n\", 'helpful/0 of 1\\n', 'rating/4.0\\n', 'title/GOOD SNEAKERS\\n', 'date/July 15, 2006\\n', 'reviewer/Christopher W. Damico \"MACMAN\"\\n', 'reviewer_location/NYC\\n', \"review_text/GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\\n\"]\n",
      "['unique_id/B0009N4F6I:works_very_well:i_have_9_cats\\n', 'asin/B0009N4F6I\\n', 'product_name/Wedgie Cup Holder: Automotive\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/Works very well\\n', 'date/August 19, 2006\\n', 'reviewer/I have 9 cats\\n', 'reviewer_location/Dela where?\\n', \"review_text/I bought one today for my Mazda Tribute because I didn't like the built-in cup holders. It's actually very sturdy and fits very well.\\n\"]\n",
      "['unique_id/B0002U1SFE:love_it!:a._kurczewski\\n', 'asin/B0002U1SFE\\n', 'product_name/Baby Einstein Discover and Play Activity Center: Baby\\n', 'helpful/1 of 1\\n', 'rating/4.0\\n', 'title/Love it!\\n', 'date/November 11, 2006\\n', 'reviewer/A. Kurczewski\\n', 'reviewer_location/Detroit, MI\\n', 'review_text/My daughter loves this activity center.  I wish they would change two things about it.  I wish we could change out the toys and it folded up\\n']\n",
      "['unique_id/B0009U8XUU:one_of_the_products_i_am_pleased_with!:maggierose\\n', 'asin/B0009U8XUU\\n', 'product_name/Jonathan Product Redo Freshen-Up Mist For Hair & Skin(R): Beauty\\n', 'helpful/9 of 14\\n', 'rating/4.0\\n', 'title/One of the products I am pleased with!\\n', 'date/July 3, 2005\\n', 'reviewer/maggierose\\n', 'reviewer_location/Long Island, NY\\n', 'review_text/I bought the Shampoo Theory and Condition Theory and this Redo Freshen-Up Mist. I have normal-type hair that needs to be washed every other day -- and if I use a lot of product, it needs to be washed every day. I have very sensitive skin too. This mist worked very well on my hair, definitely freshened it up and allowed me to restyle it with a quick blow dry. And it feels awesome on my skin. Well done, Jonathan\\n']\n",
      "['unique_id/0375416811:founder_of_chick_lit:erin_oakes_\"avid_reader\"\\n', 'asin/0375416811\\n', 'product_name/Bridget Jones Diary: Books: Helen Fielding,Tracie Bennett\\n', 'helpful/\\n', 'rating/5.0\\n', 'title/Founder of chick lit\\n', 'date/August 24, 2006\\n', 'reviewer/Erin Oakes \"avid reader\"\\n', 'reviewer_location/Central PA\\n', \"review_text/Bridget Jones, modern day woman, brillant and doesn't know it, prone to accidents and mess ups but manages to come out of them.  \\n\"]\n",
      "['unique_id/B00009R6TA:great__backpack:w._mutual\\n', 'asin/B00009R6TA\\n', 'product_name/Canon Deluxe Photo Backpack 200EG for Canon EOS SLR Cameras: Camera & Photo\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/great  backpack\\n', 'date/November 12, 2006\\n', 'reviewer/W. Mutual\\n', 'reviewer_location/California\\n', \"review_text/ This is a great back pack! If there is anything I would change it would be the logo on the front. It's brite and shinny, and I'd rather not advertise that I have a camera in there! I colored it in with a felt pen and it works great....... Overall, I love the backpack!!  \\n\"]\n",
      "[\"unique_id/B0006J419Q:best_earpiece_i've_owned:d._jackson\\n\", 'asin/B0006J419Q\\n', 'product_name/Jabra C150 Headset for 2.5mm Universal Headset Jack: Cell Phones & Service\\n', 'helpful/1 of 2\\n', 'rating/5.0\\n', \"title/Best earpiece I've owned\\n\", 'date/August 29, 2006\\n', 'reviewer/D. Jackson\\n', 'reviewer_location/Washington, DC USA\\n', \"review_text/I owned one of these for about three months, then it started to fall apart.  It was $30 at Best Buy.  I haven't replaced it, as $30 is a *lot*.\\n\"]\n",
      "['unique_id/B0009Z3K9E:you_can\\'t_go_wrong_with_\"dawn_of_sorrow.\":k._m._bowles_\"i_like_pie\"\\n', 'asin/B0009Z3K9E\\n', 'product_name/Castlevania Dawn of Sorrow: Computer &amp; Video Games\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/You can\\'t go wrong with \"Dawn of Sorrow.\"\\n', 'date/October 7, 2006\\n', 'reviewer/K. M. Bowles \"I Like pie\"\\n', 'reviewer_location/VA Beach, VA\\n', \"review_text/Castlevania: Dawn of Sorrow is the latest iteration of Konami's decades-old franchise and the first to appear on the Nintendo DS. Don't let the title fool you; this really isn't the dawn of anything, except maybe a bunch more Castlevania games on the DS. And the subtitle here is simply a workable way to include the letters D and S in the title of the game, as seems to be the requirement for the platform at this point. Dawn of Sorrow actually takes place a year after the events in Aria of Sorrow, which came out in 2003 on the Game Boy Advance. If you've played that game--or if you've played just about any recent Castlevania game actually--you'll be right at home with Dawn of Sorrow, because it's basically the same game repackaged to fit the DS. That isn't a bad thing though, because the Castlevania games have long carried the torch for good, old-fashioned 2D side-scrolling gameplay, and Dawn of Sorrow keeps that flame burning as bright as ever. \\n\"]\n",
      "['unique_id/B0000TG9E2:excellent_fantasy,_with_provisos_:lonnie_e._holder_\"the_review\\'s_the_thing\"\\n', 'asin/B0000TG9E2\\n', \"product_name/Alice in Wonderland (Masterpiece Edition): DVD: Kathryn Beaumont,Ed Wynn,Richard Haydn,Sterling Holloway,Jerry Colonna,Verna Felton,J. Pat O'Malley,Bill Thompson,Heather Angel,Joseph Kearns,Larry Grey,Queenie Leonard,Dink Trout,Doris Lloyd,James MacDonald (II),Bill Lee (IV),Thurl Ravenscroft,Max Smith,Bob Hamlin,Don Barclay,Wilfred Jackson,Clyde Geronimi,Hamilton Luske\\n\", 'helpful/7 of 12\\n', 'rating/4.0\\n', 'title/Excellent Fantasy, with Provisos \\n', 'date/July 3, 2006\\n', 'reviewer/Lonnie E. Holder \"The Review\\'s the Thing\"\\n', 'reviewer_location/Sullivan, Illinois United States\\n', 'review_text/The story of \"Alice in Wonderland\" was controversial from the moment that the Reverend Charles Lutwidge Dodgson, aka Lewis Carroll, wrote it.  Some took the story as horror rather than a childhood fantasy.  Others consider Alice\\'s journey as a trip into or through insanity.  For better or worse, Disney did capture many of these elements, and the same criticisms of the books that form the basis of this film apply to the film.  However, there are also those who loved the books and loved the film.  Normally I recommend Disney classis without reservations.  In the case of this movie, I will keep a couple of provisos.\\n']\n",
      "['unique_id/B00008SCFU:fast_and_accurate:j._n._fong\\n', 'asin/B00008SCFU\\n', 'product_name/Kingston 256 MB Secure Digital Card ( SD/256 ): Electronics\\n', 'helpful/\\n', 'rating/5.0\\n', 'title/Fast and Accurate\\n', 'date/March 19, 2006\\n', 'reviewer/J. N. Fong\\n', 'reviewer_location/Castro Valley, CA  USA\\n', 'review_text/I received my Kingston 256MB SD card just as advertised.\\n']\n",
      "['unique_id/B0000TVVEA:an_excellent_italian_gift_basket._.,:stewart__l\\n', 'asin/B0000TVVEA\\n', 'product_name/Italian Gift Basket - Classic (3.8 Pound) by igourmet.com: Gourmet Food\\n', 'helpful/5 of 11\\n', 'rating/5.0\\n', 'title/An excellent italian gift basket. .,\\n', 'date/November 24, 2005\\n', 'reviewer/stewart  L\\n', 'reviewer_location/flushing ,ny\\n', 'review_text/This italian gift basket,captures the feeling of italy,at it best...When you send this to family or friends,they will definitly,feel the love and warmth,of italy,and is sure to please...5 star recommended..\\n']\n",
      "['unique_id/B000CN7BNE:fantastically_refreshing!:sn\\n', 'asin/B000CN7BNE\\n', 'product_name/Zico Pure Coconut Water, Passion Fruit with Orange Peel Flavor, 11-Ounce Units (Pack of 12): Grocery\\n', 'helpful/\\n', 'rating/4.0\\n', 'title/fantastically refreshing!\\n', 'date/November 18, 2006\\n', 'reviewer/SN\\n', 'reviewer_location/Austin,TX\\n', \"review_text/I bought the natural flavour. Didn't find it very palatable the first time. But the next time was much better and now I am hooked on to it! An acquired taste, indeed! The 11-ounce is difficult to down in one go, though.\\n\"]\n",
      "['unique_id/B00006WNPU:omron_body_fat_analyyzer:nicholas_tompanis\\n', 'asin/B00006WNPU\\n', 'product_name/Omron HBF-306 Body Fat Analyzer: Health & Personal Care\\n', 'helpful/5 of 6\\n', 'rating/5.0\\n', 'title/Omron Body Fat Analyyzer\\n', 'date/August 19, 2006\\n', 'reviewer/Nicholas Tompanis\\n', 'reviewer_location/Virginia Beach, VA\\n', \"review_text/I've found the Omron very easy and practical to use.  It gives very good estimates of body fat percentages and BMI (body mass index) which can easily be used to illustrate a personal rate of progress for any dietary or weight training program.  For the money, it would be difficult to find something better\\n\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unique_id/B000EX8N3E:outstanding_in_almost_every_way:b._siao\\n', 'asin/B000EX8N3E\\n', \"product_name/Casio Men's G-Shock Atomic Solar Watch # MTG920DA-1: Jewelry & Watches: Casio\\n\", 'helpful/\\n', 'rating/5.0\\n', 'title/Outstanding In Almost Every Way\\n', 'date/November 9, 2006\\n', 'reviewer/B. Siao\\n', 'reviewer_location/San Diego, CA\\n', 'review_text/Elegant yet tough, this particular Casio has a metal bracelet and is extremely comfortable to wear.  The display is sharp, clear, and very easy to read.  I only wish it had a thermometer.  The watch is big and looks very macho on your wrist\\n']\n",
      "['unique_id/B0002D31QU:immediate_results!:a._sanford\\n', 'asin/B0002D31QU\\n', 'product_name/Premier Gentle Spray Anti-Bark Dog Collar: Kitchen & Housewares\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/Immediate results!\\n', 'date/October 24, 2006\\n', 'reviewer/A. Sanford\\n', 'reviewer_location/Blacksburg, VA USA\\n', \"review_text/My grandma's 10 year old Yorkie just would never shut up.  He barked at our cat, at our parrot, and anything that moved really.  We bought this collar, and it worked perfectly and immediately.  One bark and it sprayed, and he would go running off...and stop barking!  I felt kinda bad for him, but his reaction was hilarious.  I couldn't stop laughing at him, poor thing.  However, he did learn that if the collar wasn't on, he wasn't going to get sprayed, so he would bark\\n\"]\n",
      "['unique_id/B00005UMOQ:good_magazine:david_allen_hazlewood\\n', 'asin/B00005UMOQ\\n', 'product_name/Body + Soul: Magazines\\n', 'helpful/\\n', 'rating/5.0\\n', 'title/Good magazine\\n', 'date/November 15, 2006\\n', 'reviewer/David Allen Hazlewood\\n', 'reviewer_location/Tacoma, WA\\n', 'review_text/I was sceptical at first. But after getting a few of the magazines I really got into the way they looked at the Whole Body health and didn\\'t JUST focus on \"body\" exercises like most magazines\\n']\n",
      "['unique_id/B00008QS9V:it\\'s_a_mighty_wind_a_blowin\\'!:carla_j._dinsmore_\"acoustic_music_junkie\"\\n', 'asin/B00008QS9V\\n', 'product_name/A Mighty Wind: The Album: Music: Various Artists\\n', 'helpful/\\n', 'rating/5.0\\n', \"title/It's a Mighty Wind a blowin'!\\n\", 'date/July 5, 2006\\n', 'reviewer/Carla J. Dinsmore \"Acoustic music junkie\"\\n', 'reviewer_location/Wilmington, DE USA\\n', \"review_text/This is a wonderful album, that evokes memories of the 60's folk boom, yet contains original songs. I was amazed at the fantastic harmonies and musical arrangements.\\n\"]\n",
      "[\"unique_id/B000CNTDY4:good_series_if_you're_interested_in_rock,_and_metal.:a._bailey\\n\", 'asin/B000CNTDY4\\n', 'product_name/Metal Method Complete Basic Course Level 1 Thru Level 6 on DVD Doug Marks Classic Rock: Musical Instruments\\n', 'helpful/1 of 1\\n', 'rating/4.0\\n', \"title/Good Series if you're interested in Rock, and Metal.\\n\", 'date/June 15, 2006\\n', 'reviewer/A. Bailey\\n', 'reviewer_location/New York, NY\\n', 'review_text/The videos are amazing! I would have to say better than amazing. The riffs, and solos that are taught are fun and work well with the level they correspond to, and I feel progresses well with a beginner and beyond at a consistant speed. The only problem is... that there is a grey area that overlaps the term beginner and intermediate so you may have to skip around the lessons to get on track with the course. For instance I decided to learn the riffs and practice the pull offs from the beginner DVDs and go straight into the intermediate levels of the course as the beginner sections where way to easy. But I would have to say if powerful riffs and electrifying solos is your passion then I know of no other course that will get you there quicker while having more fun doing it\\n']\n",
      "['unique_id/B0007LTJFO:excellent:book_reader_\"sam\"\\n', 'asin/B0007LTJFO\\n', 'product_name/Study Stand Wire Book Stand, 9-3/8\"x6\"x5-3/8\", Chrome Finish FEL10024: Office Products\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/Excellent\\n', 'date/August 12, 2006\\n', 'reviewer/Book Reader \"Sam\"\\n', 'reviewer_location/Baden, PA United States\\n', 'review_text/This wire stand will hold large books easily and will allow you to turn the pages with ease. I should have bought two of them.\\n']\n",
      "['unique_id/B00006WS5E:ignore_all_the_bad_press,_this_is_great:harriet_epstein_falkin_\"larry\"\\n', 'asin/B00006WS5E\\n', 'product_name/Brinkmann 810-5000-0 All-In-One Gas Outdoor Cooker: Outdoor Living\\n', 'helpful/\\n', 'rating/5.0\\n', 'title/Ignore all the bad press, this is great\\n', 'date/July 5, 2006\\n', 'reviewer/Harriet Epstein Falkin \"larry\"\\n', 'reviewer_location/Los Angeles, CA USA\\n', 'review_text/I use this BBQ with Mesquite lump charcoal and have grilled excellent steaks, and smoked some pork ribs, a chicken, a London Broil and a giant hamburger so far.  No marinade, just a dry rub and on the grill.  The book included has accurate cook times as long as you keep the temperature needle on the \"i\" in Ideal for as much of the cook time as possible, which is not hard to do.  Make sure to \"cure\" it before you use it.  This burns off all the smells and chemicals that are in it from the manufacturing. Cure it using the propane burner.   Easy to assemble too\\n']\n",
      "['unique_id/B00081I76A:photoshop_cs2_wow!:orvsal\\n', 'asin/B00081I76A\\n', 'product_name/Adobe Photoshop CS2: Software\\n', 'helpful/\\n', 'rating/5.0\\n', 'title/Photoshop CS2 WOW!\\n', 'date/November 9, 2006\\n', 'reviewer/OrvSal\\n', 'reviewer_location/Sacramento,Ca\\n', 'review_text/I am amazed what this program can do. It is a big difference from PS 5.5. It is a new learning curve but well worth it. What used to take me hours to do is now an action and done in 2 minutes. Amazon had the best price for me from a source I trust ordering from. It is worth it\\n']\n",
      "['unique_id/B00024J7C6:which_is_the_biggest_monster:man_from_u.k._\"inside_canon\"\\n', 'asin/B00024J7C6\\n', 'product_name/Toilet Monster: Sports &amp; Outdoors\\n', 'helpful/14 of 22\\n', 'rating/5.0\\n', 'title/Which is the biggest monster\\n', 'date/January 30, 2006\\n', 'reviewer/Man From U.K. \"Inside Canon\"\\n', 'reviewer_location/MD USA\\n', \"review_text/This monster is great...my old millionaire nan came over recently to tell us that she was about to take us out of her will because we had too much money already, and as luck would have it she had to use the bathroom during that same visit. We heard this scream from the bathroom and when we broke in we found our nan dead on the floor...luckily she hadn't gone to her attorney's office to sign the new will and we got our share after all...thanks toilet monster..you were worth the $15 + $5 shipping we paid for you\\n\"]\n",
      "['unique_id/B000630AR4:make_life_easier:m._i._guerrero_\"sunsad\"\\n', 'asin/B000630AR4\\n', 'product_name/Car Wash Wipes: Tools & Hardware\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/make life easier\\n', 'date/March 16, 2006\\n', 'reviewer/M. I. Guerrero \"sunsad\"\\n', 'reviewer_location/\\n', \"review_text/These are great cleaning wipes. Living here on the east coast when it snows and the salt and road dirt get all over the car it's not so easy to get to a car wash right away, pull one of these out and it cleans so well and leaves a great shine. My husband and I use these even after going to a car wash when you see water spots just 1 sheet will clean it all up. I hope they don't stop making them. Lately have not been able to find them in the stores....\\n\"]\n",
      "['unique_id/B0006I5G3M:now_a_clue_mystery_game_with_more_mysteries_to_solve!:melissa_lewis_\"sunflowergirl\"\\n', 'asin/B0006I5G3M\\n', 'product_name/Clue Mysteries: Toys &amp; Games\\n', 'helpful/7 of 9\\n', 'rating/4.0\\n', 'title/Now a clue mystery game with more mysteries to solve!\\n', 'date/May 31, 2006\\n', 'reviewer/Melissa Lewis \"Sunflowergirl\"\\n', 'reviewer_location/PA, USA\\n', 'review_text/Excellent product! I really appreciate the option to choose any of the 50 given mystery cases to solve. After playing all 50, you can just start all over again! Fun, fun, fun game! THANKS\\n']\n",
      "['unique_id/6301968972:just_as_true_today!:gary_d._thomas_\"brass_crass\"\\n', 'asin/6301968972\\n', 'product_name/Hucksters: Video: Clark Gable,Deborah Kerr,Sydney Greenstreet,Adolphe Menjou,Ava Gardner,Keenan Wynn,Edward Arnold,Aubrey Mather,Richard Gaines,Frank Albertson,Douglas Fowley,Clinton Sundberg,Gloria Holden,Connie Gilchrist,Kathryn Card,Lillian Bronson,Vera Marshe,Ralph Bunker,Virginia Dale,Jimmy Conlin,Jack Conway\\n', 'helpful/1 of 1\\n', 'rating/5.0\\n', 'title/Just as true today!\\n', 'date/August 4, 2000\\n', 'reviewer/Gary D. Thomas \"Brass Crass\"\\n', 'reviewer_location/Studio City, CaliforniA\\n', 'review_text/Picture this: Clark Gable and the whole passle of MGM stars and starlets!  Spins a great story, and all this in 1947, could be today, except they  dressed better. You will not forget the characterizations, especially  Sydney Greenstreet, eat your heart out Eddie Murphy, just a marvy little  film for all ages (God I love cliches!\\n']\n"
     ]
    }
   ],
   "source": [
    "df_24_Postif = pd.DataFrame(columns=['unique_id','asin','product_name','helpful','rating','title',\n",
    "                    'date','reviewer','reviewer_location','review_text'])\n",
    "df_24_Negatif = pd.DataFrame(columns=['unique_id','asin','product_name','helpful','rating','title',\n",
    "                    'date','reviewer','reviewer_location','review_text'])\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for Rev in PositifReviews:\n",
    "    print(Rev['review1'])\n",
    "    df = Porcessing_Dictonnary_ToDataFrame(Rev)\n",
    "    #print(len(df))\n",
    "    #print(df.head(n=2))\n",
    "    df_24_Postif = pd.concat([df_24_Postif, df])\n",
    "    df.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9057a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "for Rev in NegativeReviews:\n",
    "    #print(Reviews['review1'])\n",
    "    df1 = Porcessing_Dictonnary_ToDataFrame(Rev)\n",
    "    #print(len(df))\n",
    "    #print(df.head(n=2))\n",
    "    df_24_Negatif = pd.concat([df_24_Negatif, df1])\n",
    "    df1.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89acae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>product_name</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>reviewer_location</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "      <td>16576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>15442</td>\n",
       "      <td>10905</td>\n",
       "      <td>10760</td>\n",
       "      <td>908</td>\n",
       "      <td>2</td>\n",
       "      <td>13359</td>\n",
       "      <td>1664</td>\n",
       "      <td>13427</td>\n",
       "      <td>5730</td>\n",
       "      <td>14661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B00005OLX1:sucks_sucks:jason</td>\n",
       "      <td>B00099QAQK</td>\n",
       "      <td>TIME [6-month subscription] [with $5 Bonus]: M...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>January 9, 2007</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>2748</td>\n",
       "      <td>10443</td>\n",
       "      <td>78</td>\n",
       "      <td>216</td>\n",
       "      <td>452</td>\n",
       "      <td>3572</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           unique_id        asin  \\\n",
       "count                          16576       16576   \n",
       "unique                         15442       10905   \n",
       "top     B00005OLX1:sucks_sucks:jason  B00099QAQK   \n",
       "freq                               4          18   \n",
       "\n",
       "                                             product_name helpful rating  \\\n",
       "count                                               16576   16576  16576   \n",
       "unique                                              10760     908      2   \n",
       "top     TIME [6-month subscription] [with $5 Bonus]: M...            1.0   \n",
       "freq                                                   20    2748  10443   \n",
       "\n",
       "               title             date reviewer reviewer_location review_text  \n",
       "count          16576            16576    16576             16576       16576  \n",
       "unique         13359             1664    13427              5730       14661  \n",
       "top     Disappointed  January 9, 2007                                         \n",
       "freq              78              216      452              3572          61  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_24_Negatif))\n",
    "df_24_Postif.describe()\n",
    "df_24_Negatif.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5c6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24_Postif['Class'] = \"pos\" # review positives\n",
    "df_24_Negatif['Class'] = \"neg\" #review Negatif\n",
    "Reviews  = pd.concat([df_24_Postif,df_24_Negatif])\n",
    "Reviews.drop('unique_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc61e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews.iloc[0,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9f93d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m RegexpTokenizer(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(Sent)\n\u001b[1;32m---> 15\u001b[0m Words,Sents \u001b[38;5;241m=\u001b[39m tokenize_words_Sents(\u001b[43mReviews\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWords \u001b[39m\u001b[38;5;124m\"\u001b[39m,Words)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSents \u001b[39m\u001b[38;5;124m\"\u001b[39m,Sents)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Reviews' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "#nltk.download()\n",
    "#nltk.download('punkt')\n",
    "def tokenize_words_Sents(Sent):\n",
    "    return word_tokenize(Sent),sent_tokenize(Sent)\n",
    "def tokenize_words(Sent):\n",
    "    return word_tokenize(Sent)   \n",
    "def RegExpTokenizer(Sent):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(Sent)\n",
    "\n",
    "Words,Sents = tokenize_words_Sents(Reviews.iloc[0,8])\n",
    "print(\"Words \",Words)\n",
    "print(\"Sents \",Sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc259bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'been', 'now', 'wasn', \"mightn't\", 'they', 'above', \"couldn't\", \"won't\", 'being', 'am', 'because', 'from', 'again', 'why', 've', 'didn', 'doesn', 'hadn', \"weren't\", 'she', 'weren', 'ourselves', \"wasn't\", 'during', 's', 'were', 'll', 'further', 'have', 'just', 'about', 'here', 'and', 'not', 'so', 'are', 'with', \"you'll\", 'by', \"don't\", 'be', 'through', 'an', 'o', 'own', 'my', \"wouldn't\", \"she's\", 'or', 'to', 'between', 'until', 'of', 'we', 'this', 'ain', 'into', 'will', 'other', 'y', 'm', 'off', \"that'll\", \"needn't\", 'each', 'is', 'me', 'does', 'having', 'he', 'what', 'for', \"didn't\", 'at', 'once', 't', 'under', \"should've\", 'itself', 'him', 'over', 'the', 'theirs', 'their', 'same', 'mustn', 'ours', 'below', 'our', \"mustn't\", 'too', 'ma', 'these', 'whom', 'should', 'wouldn', 'hers', 'that', 'if', 'myself', 'had', 'it', 'both', 'yourself', \"you're\", 'while', 'on', 'couldn', 'yourselves', \"hadn't\", 'shouldn', 'there', 'hasn', \"shan't\", 'those', 'isn', \"aren't\", 'them', \"isn't\", 'shan', 'but', 'against', 'down', 'themselves', 'such', 'its', 'doing', 'did', 'how', 'haven', 'was', 'has', 'when', 'more', 'only', \"you'd\", 'himself', \"you've\", 'mightn', 'herself', \"shouldn't\", 'yours', \"doesn't\", 'out', 'her', 'up', 'can', 'i', 'your', 'after', 'needn', \"hasn't\", 'do', 'a', 'all', 'any', 'd', 're', 'his', 'some', 'won', 'very', 'no', 'don', 'nor', 'few', 'in', 'aren', 'where', 'then', 'you', 'who', 'most', 'which', 'than', 'before', \"haven't\", 'as', \"it's\"}\n",
      "------------------Words ------------------------\n",
      "['GOOD', 'LOOKING', 'KICKS', 'IF', 'YOUR', 'KICKIN', 'IT', 'OLD', 'SCHOOL', 'LIKE', 'ME', '.', 'AND', 'COMFORTABLE', '.', 'AND', 'RELATIVELY', 'CHEAP', '.', 'I', \"'LL\", 'ALWAYS', 'KEEP', 'A', 'PAIR', 'OF', 'STAN', 'SMITH', \"'S\", 'AROUND', 'FOR', 'WEEKENDS']\n",
      "------------------Words filltred---------------------\n",
      "['GOOD', 'LOOKING', 'KICKS', 'IF', 'YOUR', 'KICKIN', 'IT', 'OLD', 'SCHOOL', 'LIKE', 'ME', '.', 'AND', 'COMFORTABLE', '.', 'AND', 'RELATIVELY', 'CHEAP', '.', 'I', \"'LL\", 'ALWAYS', 'KEEP', 'A', 'PAIR', 'OF', 'STAN', 'SMITH', \"'S\", 'AROUND', 'FOR', 'WEEKENDS']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "def Eliminate_Stop_Words(Sent):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = []\n",
    "    for w in Sent:\n",
    "        if w not in stop_words:\n",
    "            filtered_words.append(w)\n",
    "    return stop_words,filtered_words\n",
    "\n",
    "def Eliminate_Stop_Word(Sent):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = []\n",
    "    for w in Sent:\n",
    "        if w not in stop_words:\n",
    "            filtered_words.append(w)\n",
    "    return filtered_words\n",
    "\n",
    "stop_words,filtered_words = Eliminate_Stop_Words(Words)\n",
    "print(stop_words)\n",
    "print(\"------------------Words ------------------------\")\n",
    "print(Words)\n",
    "print(\"------------------Words filltred---------------------\")\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74c68145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'look', 'kick', 'if', 'your', 'kickin', 'it', 'old', 'school', 'like', 'me', '.', 'and', 'comfort', '.', 'and', 'rel', 'cheap', '.', 'i', \"'ll\", 'alway', 'keep', 'a', 'pair', 'of', 'stan', 'smith', \"'s\", 'around', 'for', 'weekend']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "def Stemming_Words(Words):\n",
    "    Ps = PorterStemmer()\n",
    "    Stemmed_Words = []\n",
    "    for m in Words:\n",
    "        Stemmed_Words.append(Ps.stem(m))\n",
    "    return Stemmed_Words\n",
    "Stemmed_Words = Stemming_Words(filtered_words)\n",
    "print(Stemmed_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ecc3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GOOD', 'LOOKING', 'KICKS', 'IF', 'YOUR', 'KICKIN', 'IT', 'OLD', 'SCHOOL', 'LIKE', 'ME', '.', 'AND', 'COMFORTABLE', '.', 'AND', 'RELATIVELY', 'CHEAP', '.', 'I', \"'LL\", 'ALWAYS', 'KEEP', 'A', 'PAIR', 'OF', 'STAN', 'SMITH', \"'S\", 'AROUND', 'FOR', 'WEEKENDS']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "def Lemmatizing_Words(Words):\n",
    "    Lm = WordNetLemmatizer()\n",
    "    Lemmatized_Words = []\n",
    "    for m in Words:\n",
    "        Lemmatized_Words.append(Lm.lemmatize(m))\n",
    "    return Lemmatized_Words\n",
    "\n",
    "Lemmatized_Words = Lemmatizing_Words(filtered_words)\n",
    "print(Lemmatized_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1421520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['These', 'sunglasses', 'are', 'all', 'right', 'They', 'were', 'a', 'little', 'crooked', 'but', 'still', 'cool']\n",
      "['These', 'sunglasses', 'right', 'They', 'little', 'crooked', 'still', 'cool']\n",
      "['These', 'sunglass', 'right', 'They', 'little', 'crooked', 'still', 'cool']\n"
     ]
    }
   ],
   "source": [
    "#GEt words from Review_text m3neha Tokenize \n",
    "#RegExpTokenizer to get rid of ponctuation\n",
    "ListWords =  [RegExpTokenizer(m) for m in list(Reviews['review_text'])]\n",
    "print(ListWords[1])\n",
    "#Eliminate Stop_Words\n",
    "ListWords =  [Eliminate_Stop_Word(m) for m in ListWords]\n",
    "print(ListWords[1])\n",
    "#Stemming\n",
    "ListWords = [Lemmatizing_Words(m) for m in ListWords]\n",
    "print(ListWords[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7b64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "def Bag_Of_Words(ListWords):\n",
    "    all_words = []\n",
    "    for m in ListWords:\n",
    "        for w in m:\n",
    "            all_words.append(w.lower())\n",
    "    all_words = FreqDist(all_words)\n",
    "    #print(all_words.most_common(300))\n",
    "    #print(len(all_words.keys()))\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4667247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AneeshDixit\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# visualize food data\n",
    "from sklearn.manifold import TSNE\n",
    "all_words = Bag_Of_Words(ListWords)\n",
    "count = []\n",
    "Words  = []\n",
    "for w in all_words.most_common(10):\n",
    "    count.append(w[1])\n",
    "    Words.append(w[0])\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.barplot(Words,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55814a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ListWords To lower case\n",
    "def eliminate_irrelevent_Words(ListWords):\n",
    "    ListWords1 = [] \n",
    "    for m in ListWords:\n",
    "        l = [item.lower() for item in m]\n",
    "        ListWords1.append(l)\n",
    "    ListWords = ListWords1\n",
    "    #print(ListWords)\n",
    "    #elimnate words\n",
    "    for m in ListWords:\n",
    "        for w in m:\n",
    "            if len(w) <=3:\n",
    "                m.remove(w)\n",
    "            if w == 'this':\n",
    "                m.remove(w)\n",
    "    return ListWords\n",
    "def eliminate_irrelevent_Word(Word):\n",
    "    #print(ListWords)\n",
    "    #elimnate words\n",
    "    Word = RegExpTokenizer(Word)\n",
    "    Word = [item.lower() for item in Word]\n",
    "    for m in Word:\n",
    "        if len(m) <=3:\n",
    "            Word.remove(m)\n",
    "        if m == 'this':\n",
    "            Word.remove(m)\n",
    "    return Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663bff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['GOOD', 'LOOKING', 'KICKS', 'IF', 'YOUR', 'KICKIN', 'IT', 'OLD', 'SCHOOL', 'LIKE', 'ME', 'AND', 'COMFORTABLE', 'AND', 'RELATIVELY', 'CHEAP', 'I', 'LL', 'ALWAYS', 'KEEP', 'A', 'PAIR', 'OF', 'STAN', 'SMITH', 'S', 'AROUND', 'FOR', 'WEEKENDS'], 'pos')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def Create_Document(Reviews,ListWords):\n",
    "    ListClass = list(Reviews['Class'])\n",
    "    Documents =  []\n",
    "    for m in range(len(ListWords)):\n",
    "        Documents.append((ListWords[m],ListClass[m]))\n",
    "    print(Documents[0])\n",
    "    #shuffle\n",
    "    random.shuffle(Documents)\n",
    "    return Documents\n",
    "#on va utiliser Reviews Books\n",
    "Documents = Create_Document(Reviews,ListWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16507159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': False, 'the': False, 'it': False, 'one': False, 'this': False, 'like': False, 'great': False, 'would': False, 'time': False, 'get': False, 'good': False, 'product': False, 'use': False, 'well': False, 'work': False, 'year': False, 'love': False, 'really': False, 'bought': False, 'even': False, 'first': False, 'much': False, 'also': False, 'make': False, 'book': False, 'movie': False, 'game': False, 'my': False, 'buy': False, 'thing': False, 'better': False, 'little': False, 'got': False, 'if': False, 'back': False, 'used': False, 'look': False, 'two': False, 'best': False, 'day': False, 'could': False, 'way': False, 'they': False, 'go': False, 'still': False, 'new': False, 'old': False, 'magazine': False, '2': False, 'never': False, 'price': False, 'many': False, 'easy': False, 'made': False, 'quality': False, 'camera': False, 'problem': False, 'we': False, 'think': False, 'month': False, 'know': False, 'say': False, 'read': False, 'want': False, 'take': False, 'find': False, 'review': False, 'see': False, 'film': False, 'put': False, 'money': False, 'need': False, 'lot': False, 'a': False, 'you': False, 'come': False, 'item': False, 'nice': False, 'people': False, 'but': False, 'amazon': False, 'every': False, 'found': False, 'and': False, 'using': False, 'since': False, 'play': False, 'ever': False, 'set': False, 'give': False, 'recommend': False, '5': False, 'purchased': False, 'watch': False, '3': False, 'right': False, 'long': False, 'there': False, 'another': False, 'not': False}\n"
     ]
    }
   ],
   "source": [
    "def find_features(document,all_words,nbr_word):\n",
    "    Most_Comm_Word = []    \n",
    "    for w in all_words.most_common(nbr_word):\n",
    "        Most_Comm_Word.append(w[0])\n",
    "\n",
    "    word_features = Most_Comm_Word\n",
    "    words = RegExpTokenizer(document)\n",
    "    #print(words)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "print(find_features('im road going to tunisia .',all_words,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92c8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Features_Set(all_words,Documents,nbr_word):\n",
    "    #list(all_words.keys())[:1000]\n",
    "    #featuresets = [(find_features(rev), category) for (rev, category) in Documents]\n",
    "    featuresets = []\n",
    "    for rev,cat in Documents:\n",
    "        #print(' '.join(rev),cat)\n",
    "        feature = find_features(' '.join(rev),all_words,nbr_word)\n",
    "        #print(feature)\n",
    "        featuresets.append((feature,cat))\n",
    "    return featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "178ed28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = Features_Set(all_words,Documents,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c6bb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews.to_csv(\"Reviews.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14650e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03d2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews = pd.read_csv('Reviews.csv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473ab385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOO...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These sunglasses are all right. They were a li...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't see the difference between these bodys...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very nice basic clothing.  I think the size is...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love these socks. They fit great (my 15 mont...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text Class\n",
       "0  GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOO...   pos\n",
       "1  These sunglasses are all right. They were a li...   pos\n",
       "2  I don't see the difference between these bodys...   pos\n",
       "3  Very nice basic clothing.  I think the size is...   pos\n",
       "4  I love these socks. They fit great (my 15 mont...   pos"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  Reviews.loc[:,'review_text':'Class']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7363fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOO...\n",
       "1        These sunglasses are all right. They were a li...\n",
       "2        I don't see the difference between these bodys...\n",
       "3        Very nice basic clothing.  I think the size is...\n",
       "4        I love these socks. They fit great (my 15 mont...\n",
       "                               ...                        \n",
       "38543    I live in the UK and Amazon doesn't allow me t...\n",
       "38544    This film is about a female student at Randolp...\n",
       "38545    Let's face it. Nothing anyone says can sway a ...\n",
       "38546    I live in the UK and Amazon doesn't allow me t...\n",
       "38547    This series is being sold with missing episode...\n",
       "Name: review_text, Length: 38548, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_tags(string):\n",
    "    # removelist = \"\"\n",
    "    result = str(string)\n",
    "    # result = ' '.join(ch for ch in string if(ch.isalnum() or ' '))    #remove non-alphanumeric characters \n",
    "    # result = result.lower()\n",
    "    return result\n",
    "data['review_text']=data['review_text'].apply(lambda cw : remove_tags(cw))\n",
    "data['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e06805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "data['review_text'] = data['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08878bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38543</th>\n",
       "      <td>I live UK Amazon allow download ANY NCIS shows...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38544</th>\n",
       "      <td>This film female student Randolph University A...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38545</th>\n",
       "      <td>Let's face it. Nothing anyone say sway particu...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38546</th>\n",
       "      <td>I live UK Amazon allow download ANY NCIS shows...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38547</th>\n",
       "      <td>This series sold missing episodes, like many o...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text Class\n",
       "38543  I live UK Amazon allow download ANY NCIS shows...   neg\n",
       "38544  This film female student Randolph University A...   neg\n",
       "38545  Let's face it. Nothing anyone say sway particu...   neg\n",
       "38546  I live UK Amazon allow download ANY NCIS shows...   neg\n",
       "38547  This series sold missing episodes, like many o...   neg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "data['review_text'] = data.review_text.apply(lemmatize_text)\n",
    "data.head()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170f2730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of each review :  36.83036733423265\n",
      "Percentage of reviews with positive sentiment is 56.99906609940852%\n",
      "Percentage of reviews with negative sentiment is 43.00093390059147%\n"
     ]
    }
   ],
   "source": [
    "s = 0.0\n",
    "for i in data['review_text']:\n",
    "    word_list = i.split()\n",
    "    s = s + len(word_list)\n",
    "print(\"Average length of each review : \",s/data.shape[0])\n",
    "pos = 0\n",
    "for i in range(data.shape[0]):\n",
    "    if data.iloc[i]['Class'] == 'pos':\n",
    "        pos = pos + 1\n",
    "neg = data.shape[0]-pos\n",
    "print(\"Percentage of reviews with positive sentiment is \"+str(pos/data.shape[0]*100)+\"%\")\n",
    "print(\"Percentage of reviews with negative sentiment is \"+str(neg/data.shape[0]*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3a9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['review_text'].values\n",
    "labels = data['Class'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c933f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acfd90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "# convert train dataset to sequence and pad sequences\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d16074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 100)          300000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,601\n",
      "Trainable params: 387,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "375a668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "814/814 [==============================] - 71s 84ms/step - loss: 0.4885 - accuracy: 0.7589 - val_loss: 0.4383 - val_accuracy: 0.7880\n",
      "Epoch 2/50\n",
      "814/814 [==============================] - 57s 71ms/step - loss: 0.3801 - accuracy: 0.8323 - val_loss: 0.4156 - val_accuracy: 0.8060\n",
      "Epoch 3/50\n",
      "814/814 [==============================] - 64s 78ms/step - loss: 0.3433 - accuracy: 0.8529 - val_loss: 0.4064 - val_accuracy: 0.8077\n",
      "Epoch 4/50\n",
      "814/814 [==============================] - 68s 84ms/step - loss: 0.3031 - accuracy: 0.8719 - val_loss: 0.4272 - val_accuracy: 0.8012\n",
      "Epoch 5/50\n",
      "814/814 [==============================] - 70s 86ms/step - loss: 0.2697 - accuracy: 0.8901 - val_loss: 0.4639 - val_accuracy: 0.8015\n",
      "Epoch 6/50\n",
      "814/814 [==============================] - 66s 80ms/step - loss: 0.2367 - accuracy: 0.9071 - val_loss: 0.4992 - val_accuracy: 0.8029\n",
      "Epoch 7/50\n",
      "814/814 [==============================] - 64s 79ms/step - loss: 0.2011 - accuracy: 0.9235 - val_loss: 0.5123 - val_accuracy: 0.7929\n",
      "Epoch 8/50\n",
      "814/814 [==============================] - 67s 82ms/step - loss: 0.1732 - accuracy: 0.9372 - val_loss: 0.6015 - val_accuracy: 0.7960\n",
      "Epoch 9/50\n",
      "814/814 [==============================] - 65s 79ms/step - loss: 0.1528 - accuracy: 0.9455 - val_loss: 0.6378 - val_accuracy: 0.7860\n",
      "Epoch 10/50\n",
      "814/814 [==============================] - 66s 81ms/step - loss: 0.1275 - accuracy: 0.9560 - val_loss: 0.6825 - val_accuracy: 0.7960\n",
      "Epoch 11/50\n",
      "814/814 [==============================] - 65s 80ms/step - loss: 0.1057 - accuracy: 0.9631 - val_loss: 0.8326 - val_accuracy: 0.7901\n",
      "Epoch 12/50\n",
      "814/814 [==============================] - 64s 78ms/step - loss: 0.0914 - accuracy: 0.9682 - val_loss: 0.8133 - val_accuracy: 0.7873\n",
      "Epoch 13/50\n",
      "814/814 [==============================] - 65s 80ms/step - loss: 0.0735 - accuracy: 0.9743 - val_loss: 0.9243 - val_accuracy: 0.7867\n",
      "Epoch 14/50\n",
      "814/814 [==============================] - 60s 73ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 1.0875 - val_accuracy: 0.7932\n",
      "Epoch 15/50\n",
      "814/814 [==============================] - 56s 68ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 1.0547 - val_accuracy: 0.7849\n",
      "Epoch 16/50\n",
      "814/814 [==============================] - 56s 69ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 0.9881 - val_accuracy: 0.7808\n",
      "Epoch 17/50\n",
      "814/814 [==============================] - 60s 73ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 1.0956 - val_accuracy: 0.7856\n",
      "Epoch 18/50\n",
      "814/814 [==============================] - 58s 72ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 1.1974 - val_accuracy: 0.7835\n",
      "Epoch 19/50\n",
      "814/814 [==============================] - 56s 69ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 1.2303 - val_accuracy: 0.7960\n",
      "Epoch 20/50\n",
      "814/814 [==============================] - 55s 67ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 1.2987 - val_accuracy: 0.7922\n",
      "Epoch 21/50\n",
      "814/814 [==============================] - 56s 68ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 1.3265 - val_accuracy: 0.7870\n",
      "Epoch 22/50\n",
      "814/814 [==============================] - 56s 69ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 1.3348 - val_accuracy: 0.7929\n",
      "Epoch 23/50\n",
      "814/814 [==============================] - 56s 69ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 1.3874 - val_accuracy: 0.7967\n",
      "Epoch 24/50\n",
      "814/814 [==============================] - 56s 69ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 1.3835 - val_accuracy: 0.7922\n",
      "Epoch 25/50\n",
      "814/814 [==============================] - 57s 71ms/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 1.3840 - val_accuracy: 0.7880\n",
      "Epoch 26/50\n",
      "814/814 [==============================] - 58s 71ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 1.1355 - val_accuracy: 0.7828\n",
      "Epoch 27/50\n",
      "814/814 [==============================] - 58s 71ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 1.4439 - val_accuracy: 0.7891\n",
      "Epoch 28/50\n",
      "814/814 [==============================] - 58s 71ms/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 1.3472 - val_accuracy: 0.7901\n",
      "Epoch 29/50\n",
      "814/814 [==============================] - 58s 72ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 1.4767 - val_accuracy: 0.7901\n",
      "Epoch 30/50\n",
      "814/814 [==============================] - 59s 72ms/step - loss: 0.0154 - accuracy: 0.9938 - val_loss: 1.5807 - val_accuracy: 0.7953\n",
      "Epoch 31/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 1.5912 - val_accuracy: 0.7939\n",
      "Epoch 32/50\n",
      "814/814 [==============================] - 59s 72ms/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 1.4245 - val_accuracy: 0.7925\n",
      "Epoch 33/50\n",
      "814/814 [==============================] - 60s 74ms/step - loss: 0.0150 - accuracy: 0.9942 - val_loss: 1.6019 - val_accuracy: 0.7860\n",
      "Epoch 34/50\n",
      "814/814 [==============================] - 59s 72ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 1.4910 - val_accuracy: 0.7863\n",
      "Epoch 35/50\n",
      "814/814 [==============================] - 59s 72ms/step - loss: 0.0217 - accuracy: 0.9916 - val_loss: 1.4023 - val_accuracy: 0.7911\n",
      "Epoch 36/50\n",
      "814/814 [==============================] - 60s 74ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.6439 - val_accuracy: 0.7915\n",
      "Epoch 37/50\n",
      "814/814 [==============================] - 59s 73ms/step - loss: 0.0104 - accuracy: 0.9955 - val_loss: 1.8083 - val_accuracy: 0.7898\n",
      "Epoch 38/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 1.4860 - val_accuracy: 0.7922\n",
      "Epoch 39/50\n",
      "814/814 [==============================] - 63s 77ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 1.5299 - val_accuracy: 0.7908\n",
      "Epoch 40/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 1.2548 - val_accuracy: 0.7846\n",
      "Epoch 41/50\n",
      "814/814 [==============================] - 63s 78ms/step - loss: 0.0176 - accuracy: 0.9929 - val_loss: 1.4813 - val_accuracy: 0.7898\n",
      "Epoch 42/50\n",
      "814/814 [==============================] - 63s 77ms/step - loss: 0.0085 - accuracy: 0.9962 - val_loss: 1.6814 - val_accuracy: 0.7880\n",
      "Epoch 43/50\n",
      "814/814 [==============================] - 61s 75ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 1.6465 - val_accuracy: 0.7967\n",
      "Epoch 44/50\n",
      "814/814 [==============================] - 61s 75ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 1.6104 - val_accuracy: 0.7943\n",
      "Epoch 45/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0094 - accuracy: 0.9961 - val_loss: 1.7138 - val_accuracy: 0.7977\n",
      "Epoch 46/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0082 - accuracy: 0.9962 - val_loss: 1.8981 - val_accuracy: 0.7950\n",
      "Epoch 47/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 1.4635 - val_accuracy: 0.7946\n",
      "Epoch 48/50\n",
      "814/814 [==============================] - 62s 76ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 1.6195 - val_accuracy: 0.8012\n",
      "Epoch 49/50\n",
      "814/814 [==============================] - 64s 78ms/step - loss: 0.0114 - accuracy: 0.9955 - val_loss: 1.6981 - val_accuracy: 0.7922\n",
      "Epoch 50/50\n",
      "814/814 [==============================] - 63s 77ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 1.8361 - val_accuracy: 0.7988\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "history = model.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01361c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 7s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd025e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i >= 0.8:\n",
    "        pred_labels.append(5)\n",
    "    elif i>=0.6:\n",
    "        pred_labels.append(4)\n",
    "    elif i>=0.4:\n",
    "        pred_labels.append(3)\n",
    "    elif i>=0.2:\n",
    "        pred_labels.append(2)\n",
    "    elif i>0:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "        \n",
    "sum(pred_labels)/len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b0d0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f7c20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.343467884196327\n"
     ]
    }
   ],
   "source": [
    "print(sum(pred_labels)/len(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c5def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9c42c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6e9696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 12s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03de4279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb121f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
